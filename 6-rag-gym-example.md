## Understanding RAG-Gym Workings by an Example

![RAG-Gym example diagram from the RAG-Gym GitHub repository](https://github.com/RAG-Gym/RAG-Gym/blob/main/figs/rag_gym.png)

Let's walk through a step-by-step example of how RAG-Gym agentic RAG workflow, optimized with process supervision, would tackle a complex, multi-hop question. This will illustrate how the agent makes decisions at each stage and how the supervision guides it toward the most efficient path.

**The User's Question:** "What is the date of death of the director of the film Holocaust 2000?"

As we can see, this question requires a two-step reasoning process:
1.  First, identify the director of the film "Holocaust 2000."
2.  Second, find the date of death for that specific person.

---

### **Round 1**

At the beginning of the process, the agent only has the user's question. Its history of actions and findings is empty.

*   **Current State:**
    *   `Question`: "What is the date of death of the director of the film Holocaust 2000?"
    *   `History`: `[]`

The agent is now tasked with generating a set of possible next 3 actions.

*   **Candidate Actions Generated by the Agent:**
    1.  `{"type": "Search", "query": "Who directed the film Holocaust 2000?"}`
    2.  `{"type": "Search", "query": "Holocaust 2000 film details"}`
    3.  `{"type": "Answer", "data": "I do not have enough information to answer this question."}`

*   **Process Supervision Analysis (The "Judge's" Evaluation):**
    A judge (either a human annotator or a more powerful "teacher" LLM) evaluates these candidate actions based on a set of criteria to provide a process reward.
    *   **Action 1** is rated **Excellent**. It is a perfect first step. It's precise, directly targets the first piece of unknown information (the director's name), and is foundational to solving the overall question.
    *   **Action 2** is rated **Poor**. This query is too broad. While it might retrieve the director's name, it would also retrieve a lot of irrelevant information (cast, plot, release date), making it an inefficient and less useful action.
    *   **Action 3** is rated **Terrible**. The agent has not yet attempted any information retrieval. Deciding to give up at this stage is a premature and incorrect action because the current history is clearly not sufficient to provide an answer.

*   **Selected Action:**
    Based on the judge's high rating, Action 1 is selected as the best step forward.
    `{"type": "Search", "query": "Who directed the film Holocaust 2000?"}`

*   **Environment's Response (Information Retrieval):**
    The system executes the search and retrieves the following documents:
    *   `Doc 1`: "Holocaust 2000 is a 1977 Italian-British horror film directed by Alberto De Martino and starring Kirk Douglas."
    *   `Doc 2`: "The filmography of Alberto De Martino includes the cult classic Holocaust 2000, released in 1977."

*   **Updated State:**
    *   `Question`: "What is the date of death ...?"
    *   `History`:-
        ```
        [
            {
                "Query": "Who directed the film Holocaust 2000?",
                "Docs": [
                    "Holocaust 2000 is a 1977 Italian-British ...",
                    "The filmography of Alberto De Martino ..."
                ]
            }
        ]
        ```

---

### **Round 2**

The agent now has the director's name, Alberto De Martino, in its history. It uses this new information to decide its next move.

*   **Current State:** (As updated above)

*   **Candidate Actions Generated by the Agent:**
    1.  `{"type": "Search", "query": "Alberto De Martino date of death"}`
    2.  `{"type": "Search", "query": "Who directed the film Holocaust 2000?"}`
    3.  `{"type": "Answer", "data": "The director of Holocaust 2000 was Alberto De Martino."}`

*   **Process Supervision Analysis (The "Judge's" Evaluation):**
    *   **Action 1** is rated **Excellent**. It correctly synthesizes the information learned in the first step (the director's name) to formulate the query for the second, and final, piece of required information. This is a perfect example of multi-hop reasoning.
    *   **Action 2** is rated **Terrible**. This action is **redundant**. The agent is asking a question that has already been answered and is present in its history. A good process reward model would heavily penalize this action to teach the agent to avoid inefficient loops.
    *   **Action 3** is rated **Poor**. While the statement is correct, it is an incomplete answer to the user's original question. The agent has not yet found the date of death, so choosing to answer now is premature. The information in the history is not yet sufficient.

*   **Selected Action:**
    Action 1 is the clear optimal choice to move closer to the final answer.
    `{"type": "Search", "query": "Alberto De Martino date of death"}`

*   **Environment's Response (Information Retrieval):**
    The system executes the search and retrieves new documents:
    *   `Doc 3`: "Alberto De Martino, the Italian director known for films like The Antichrist and Holocaust 2000, passed away on October 31, 2015."
    *   `Doc 4`: "Alberto De Martino (12 June 1929 – 31 October 2015) was a prolific Italian film director and screenwriter."

*   **Updated State:**
    *   `Question`: "What is the date of death of the director of the film Holocaust 2000?"
    *   `History`:-
        ```
        [
            {
                "Query": "Who directed the film Holocaust 2000?",
                "Docs": [
                    "Holocaust 2000 is a 1977 Italian-British ...",
                    "The filmography of Alberto De Martino ..."
                ]
            },
            {
                "Query": "Alberto De Martino date of death",
                "Docs": [
                    "Alberto De Martino, the Italian director known for ...",
                    "Alberto De Martino (12 June 1929 – 31 October 2015) ..."
                ]
            }
        ]
        ```

---

### **Round 3**

The agent's history now contains both the director's name and his date of death. It has all the necessary components to answer the user's question.

*   **Current State:** (As updated above)

*   **Candidate Actions Generated by the Agent:**
    1.  `{"type": "Answer", "data": "The director of the film Holocaust 2000 was Alberto De Martino. He died on October 31, 2015."}`
    2.  `{"type": "Search", "query": "Alberto De Martino filmography"}`
    3.  `{"type": "Answer", "data": "October 31, 2015."}`

*   **Process Supervision Analysis (The "Judge's" Evaluation):**
    *   **Action 1** is rated **Excellent**. The information in the history is now **sufficient** to answer the question completely. This action correctly synthesizes information from both retrieval steps into a comprehensive and accurate final answer.
    *   **Action 2** is rated **Poor**. This search is unnecessary. While it's related to the topic, it does not help answer the user's specific question. The agent should recognize that it has enough information and that further searching lacks utility.
    *   **Action 3** is rated **Good, but not Excellent**. This answer is factually correct but incomplete. It doesn't provide the full context by restating the director's name, which Action 1 does. A superior agent provides a complete, self-contained answer.

*   **Selected Action:**
    Action 1 is chosen as the optimal concluding action.
    `{"type": "Answer", "data": "The director of the film Holocaust 2000 was Alberto De Martino. He died on October 31, 2015."}`

*   **Environment's Response:**
    The action type is `Answer`, which terminates the process.

### **Final Output to the User:**

The director of the film Holocaust 2000 was Alberto De Martino. He died on October 31, 2015.

This step-by-step trajectory shows how process supervision provides fine-grained feedback at each decision point, guiding the agent to make logical, efficient, and non-redundant choices. By rewarding good intermediate steps, the system learns to build a coherent and optimal path to the final answer, rather than just guessing and hoping the final result is correct.
